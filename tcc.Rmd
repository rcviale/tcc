---
title: "TCC"
author: "Rodrigo Viale"
date: "28/09/2021"
bibliography: refs.bib  
#csl: abnt.csl
output:
  bookdown::html_document2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, 
                      cache = TRUE)
```

```{r library}
library(tidyverse)
library(knitr)
```

# Introduction {#intro}

A alocação de carteiras de investimento de maneira assertiva é uma tarefa de difícil execução, uma vez que envolve invariavelmente uma pluralidade de riscos. O risco de mercado em particular nunca pode ser completamente eliminado, porém, muito se discute em termos de seu controle e minimização, principalmente através de diversificação, meio esse que depende do mapeamento correto das correlações entre os ativos. Portanto, torna-se necessária, em um processo de construção de carteiras visando a otimização de portfólios, não só a estimação da matriz de covariâncias de maneira assertiva, mas também de medidas de volatilidade precisas.

Um método muito comum e popularizado na literatura que trata da previsão de volatilidade é o GARCH (*General Autoregressive Conditional Heteroskedasticity*), introduzido por @Bollerslev86 e que é empregado em retornos diários. GARCH-type models, however, tend to overpredict volatility, as documented by @Nomikos11 when dealing with petroleum futures' time series. These models, therefore, present a slow response after a volatility shock passes, taking time for the estimates to go down.

With the growing amount, availability and managebility of data at higher frequencies (intraday) than the daily one, a richer sample covariance matrix can be estimated, leading ultimately to the construction of a matrix based on realized measures. 

Cryptocurrencies have gained notoriety over the last few years, especially because of the appreciation of Bitcoin, which had an incredible peak in 2018 that was only reached and surpassed by the end of 2020. These alternative assets are traded worldwide in various *exchanges*, private platforms that bare similarities to traditional stock and futures exchanges, like connecting buyers and sellers, but also some pecularities, like unlimited trading 24 hours a day every day of the year, which increases the amount of data per day, since negotiation is not limited to a specific time frame of each day. From 2018 many new digital currencies were introduced, each with a different purpose. These have also had noteworthy appreciation in general, with the total market cap of 50 most valued cryptocurrencies having reached over 1,9 trillion dollars ^[Source: Coinmarketcap, in September 19, 2021]. These higher returns when compared to traditional assets, however, are attained only by the increased volatility that predominates in this market.

This study aims to verify if this additional volatility is a significant factor in determining cryptocurrencies' returns and, simultaneously, if there are benefits to using high frequency data for the covariance matrix estimation, instead of a daily one.

In Chapter \@ref(litrev), a literature review about the matter is introduced, Chapter \@ref(data) briefly describes the data set, Chapter \@ref(empmet) presents the empirical methodology applied in this work, Chapter \@ref(res) presents the obtained results and finally, Chapter \@ref(conc) concludes.

# Literature Review {#litrev}

# Data Description {#data}

The data used in this work consists of ten minute-by-minute cryptocurrency prices series obtained from Binance's API ^[Source: https://api.binance.com/] and negotiated in this exchange, which is currently the largest one in the world in terms of daily trading volume of cryptocurrencies ^[Source: CoinMarketCap, at https://coinmarketcap.com/rankings/exchanges/]. It is also one of the world leaders in terms of number of "markets", where a "market" is defined as the pair of currencies that are being traded. 

This study's sample was restricted to the period between August 1, 2019 to July 31, 2021 (731 days in total), because not all series were available from the source before these dates. The analyzed cryptocurrencies are listed in Table \@ref(tab:restsample), along with each series' number of missing and available observations during this sample period. There is a total of 1,051,640 time stamps (minutes) during this time window, with 0.25% of it being of missing data. Additional information on the availability of the individual series, with each series' initial dates, can be found in Appendix \@ref(adata).

```{r restsample}
path <- "C:/Users/rodri/OneDrive/Documents/Academics/Trabalho de Conclusão de Curso/tcc/Print/"
kable(readr::read_rds(paste0(path, "rest_summ_table.rds")), 
      caption = "Series' Sample Size")
```

In order to better clean this minute-by-minute data set, missing observations were filled with the previously available price and, subsequently, the last price from each 5-minute interval was taken, constructing ten series with this frequency, which then amount to 210,528 and 288 observations in total and per day, respectively, for each asset. This periodicity was chosen based on the empirical work from @Liu15, where the authors found it is very difficult to significantly beat 5-minute realized variance when it comes to price variation estimators constructed from high-frequency data, considering a span of five asset classes to reach this conclusion.

These 5-minute closing prices series were then used to compute realized variances, $RV_{i,\ t}$, and realized volatilities, $RVOL_{i,\ t}$ for each asset, according to the formulas that will be presented in Section \@ref(measures). Daily log-returns, $r_{i,\ t}$, consisting of the sum of all 5-minute log-returns in a day, were also taken. Summary statistics for these measures for each series can be found in Appendix \@ref(asumm).

In order to weight the assets and create a theoretical index to represent the "crypto market factor", the daily market capitalization of each cryptocurrency was obtained from CoinMarketCap. The weighting procedure will be described in Section \@ref(syntwei).

# Methodology {#empmet}

The methodology used in this study combines realized measures, which are presented in Section \@ref(measures), applied to real series, i.e. the cryptocurrencies that make up the initial data set, but also to fictitious series, that are created trough the assets' weighting techniques described in Section \@ref(syntwei), constituting the final data set. At the same time, a GARCH volatility estimate is computed, according to what is depicted in Section \@ref(garch). Lastly, with this final data set and the GARCH estimates, two Fama-MacBeth regressions, as presented in Section \@ref(fmb), are computed.

## Realized Mesures {#measures}

For the purposes of this study, individual asset log returns are computed from the sum of the 5-min log returns for each cryptocurrency $i$, according to the formula below.

\begin{equation}
(\#eq:ri)
r_{i, t} = \sum_{j = 1}^{m} r_{i, t - 1 + j n}
\end{equation}

where $t$ represents a day, $n$ is a fraction of a trading session associated with the sampling frequency (since 5-min returns are being used and there are 1440 minutes in one day, $n = \frac{1}{(1440/5)} = \frac{1}{288}$) and $m$ represents the amount of observations in on day ($m = \frac{1}{n} = 288$).

Following the research from Liu et al. (2015), which concluded that it is very difficult to significantly beat a simple 5-minute realized variance ($RV$) when it comes to price variation estimators constructed from high-frequency data, this realized measure is therefore taken for the analysis conducted in this study. This estimator consists of the sum of squared 5-minute returns for each day $t$ and asset $i$, as in the formula below.

\begin{equation}
(\#eq:rv)
RV_{i,\ t} = \sum_{j = 1}^{m} r_{i,\ t - 1 + j n}^{2}
\end{equation}

where $n$ is a fraction of a trading session associated with the sampling frequency (since 5-min $RV$ is being used and there are 1440 minutes in one day, $n = \frac{1}{(1440/5)} = \frac{1}{288}$) and $m$ represents the amount of observations in on day ($m = \frac{1}{n} = 288$).

The volatility $RVOL_{i,\ t}$ provided by this estimator is then simply the square root of each $RV_{i,\ t}$.

\begin{equation}
(\#eq:rvol)
RVOL_{i,\ t} = \sqrt{RV_{i, t}}
\end{equation}

## Synthetic Market Estimates and Weighting Methods {#syntwei}

In order to create synthetic indices that are able to represent the the overall cryptocurrency market, it becomes necessary to weight the assets in order to create this index. Two methods, therefore, are employed as weighting factors: the daily market capitalization for each asset and the weights derived from the application of the Principal Component Analysis (PCA).

### Estimation Based on Market Capitalization {#mcap}

From the daily market capitalization series, weights $w_{i,\ t}$ are estimated such that

\begin{equation}
(\#eq:wi)
w_{i,\ t}^{(MC)} = \frac{MC_{i, t}}{\sum_{j = 1}^K MC_{j, t}}\\
\end{equation}

\begin{equation}
(\#eq:wmc)
W_{MC,\ t}=
\begin{bmatrix}
w_{1,\ t} \\
w_{2,\ t} \\
... \\
w_{K,\ t} \\
\end{bmatrix}
\end{equation}

where $MC_{i,\ t}$ is the market capitalization for asset $i$ in period $t$.

These weights are then combined with the assets' returns in equation \@ref(eq:ri), computed previously to obtain an estimate of *market* returns $R_{m,\ t}^{(MC)}$ such as

\begin{equation}
(\#eq:caprm)
r_{m,\ t}^{(MC)} = \sum_{i = 1}^K (r_{i,\ t} w_{i,\ t})\\
\end{equation}

\begin{equation}
(\#eq:capRm)
R_{m}^{(MC)} =
\begin{bmatrix}
r_{m,\ 1}^{(MC)} \\
r_{m,\ 2}^{(MC)} \\
... \\
r_{m,\ T}^{(MC)}
\end{bmatrix} 
=
\begin{bmatrix}
\sum_{i = 1}^K (r_{i,\ 1} w_{i,\ 1}) \\
\sum_{i = 1}^K (r_{i,\ 2} w_{i,\ 2}) \\
... \\
\sum_{i = 1}^K (r_{i,\ T} w_{i,\ T})
\end{bmatrix}.
\end{equation}

This vector will be the first regressor in the Fama-MacBeth estimation.

Testing the market's volatility as a driver of returns is the main goal of this work, however, obtaining an estimate for the market's volatility is quite more tricky. The variance can not be weighted in the same fashion as what was done for assets' returns, because of the covariance between assets ^[Explain why variance can't be multiplied and summed up.], and also, there is no 5-minute market returns series (only daily), where the sum of squared returns could be taken, similarly as to what was done with the individual cryptocurrencies. To obtain an estimate for the market's 5-minute realized variance, therefore, firstly the 5-minute sample covariance matrix for each period must be estimated

\begin{equation}
(\#eq:rcovix)
RCov_{t} = 
\begin{bmatrix} 
s_{11,\ t}^2 & s_{12,\ t}^2 & ... & s_{1K,\ t}^2\\
s_{21,\ t}^2 & s_{22,\ t}^2 & ... & s_{2K,\ t}^2\\
... & ... & ... & ...\\
s_{K1,\ t}^2 & s_{K2,\ t}^2 & ... & s_{KK,\ t}^2\\
\end{bmatrix},
\end{equation}

where $s_{ij,\ t}^2$ denotes the 5-minute sample covariance between assets $i$ and $j$ in day $t$. This matrix can then be simply weighted by the $W_{MC,\ t}$ vectors obtained from the assets' market capitalization in equation \@ref(eq:wmc) in the following way.

\begin{equation}
(\#eq:caprv)
RV_{m,\ t}^{(MC)} = W_{MC,\ t}^T \times RCov_{t} \times W_{MC,\ t},
\end{equation}

where superscript $T$ is denotes the transposed of the vector in question. The volatility for each period $t$ is therefore obtained simply by taking square root of the obtained realized variance estimate: 

\begin{equation}
(\#eq:caprvol)
RVOL_{m,\ t}^{(MC)} = \sqrt{RV_{m,\ t}^{(MC)}}
\end{equation}

### Estimation Based on Principal Component Analysis {#pca}

An alternative method used to obtain an estimate for the market's returns and volatility is through Principal Component Analysis (PCA), introduced by @Pearson1901. In a context of closely related variables such as this data set (see the series' correlation matrix in Appendix \@ref(acor), @Brooks19 noted that PCA can be particularly useful, because it can transform the $K$ series into a new set of $K$ uncorrelated variables, by taking linear combinations of the original data set. In other terms, as Brooks presents

\begin{array}{ccccccccc}
(\#eq:pca)
p_{1, t}  & = & \alpha_{11, t} r_{1, t} & + & \alpha_{12, t} r_{2, t} & + & ... & + & \alpha_{1K, t} r_{K, t} \\
p_{2, t}  & = & \alpha_{21, t} r_{1, t} & + & \alpha_{22, t} r_{2, t} & + & ... & + & \alpha_{2K, t} r_{K, t} \\
...  & = & ...                & + & ...                 & + & ... & + & ... \\
p_{K, t}  & = & \alpha_{K1, t} r_{1, t} & + & \alpha_{K2, t} r_{2, t} & + & ... & + & \alpha_{KK, t} r_{K, t} \\
\end{array}

where $p_{i, t}$ and $r_{i, t}$, represent, respectively, the $i$ principal component and original variable (5-minute return) in period $t$, and $\alpha_{ij, t}$ denotes the coefficient for variable $j$ in the principal component $i$ in day $t$. The sum of the squared coefficients $\alpha^2$ that were estimated must be equal to one for each individual component, as in equation \@ref(eq:condpca). The variables have to be standardized before the application of this method, although this step is not necessary in this study since it will work with log-returns and not prices' series. 

\begin{equation}
(\#eq:condpca)
\sum_{j = 1}^K \alpha_{i,\ j}^2 = 1 \ \forall \ i = 1,\ 2,\ ...,\ K.
\end{equation}

This procedure is, therefore, carried out for the 5-minute returns series for each day $t$ in the analyzed period, and from the estimated principal components, the first one, which is able to explain the largest amount of the data's variance (56% on average during the sampled period, see Appendix \@ref(apca) for additional information on PCA's application), is taken as the returns for an index to represent the cryptocurrencies market in the same fashion as the market cap weighted index constructed in Section \@ref(mcap). This first component is already weighted itself, so there is no need for any further calculations for these *market returns*. 

Computing the realized volatility of the market however, requires a weighting vector to apply the same matrix multiplication as in Section \@ref(mcap). This vector is obtained from the weights attributed to each asset by the first principal component, which are the squared coefficients $\alpha_{1j, t}$ from equation \@ref(eq:condpca) for each day $t$, in the form of equation \@ref(eq:wpca). 

\begin{equation}
(\#eq:wpca)
W_{PCA,t} = 
\begin{bmatrix}
\alpha_{11, t}^2 \\
\alpha_{12, t}^2 \\
...\\
\alpha_{1K, t}^2
\end{bmatrix}
\end{equation}

The market realized variance is then obtained in the same fashion as in the market capitalization case presented in equation \@ref(eq:caprv), that is, by multiplying the transposed PCA weights vector by the 5-minute sample covariance matrix and then the PCA weights vector, as showed in equation \@ref(eq:pcarv) and the realized volatility is again computed by taking the square root of $RV_t$.

\begin{equation}
(\#eq:pcarv)
RV_{m,t}^{(PCA)} = W_{PCA,t}^T \times RCov_t \times W_{PCA,t}.
\end{equation}

\begin{equation}
(\#eq:pcarvol)
RVOL_{m,t}^{(PCA)} = \sqrt{RV_{m,t}^{(PCA)}}
\end{equation}

With these, there are two measures to represent the cryptocurrencies market derived from PCA and two derived from market capitalization of individual assets, with one in each case being for market returns and the other one for realized volatility. 

In the next subsection, a GARCH model is presented as an alternative volatility estimator.

## GARCH Model {#garch}

According to empirical studies from @Hansen05, where the authors compared the forecast potential of a total of 330 ARCH-type models, there is "no evidence that a GARCH(1, 1) is outperformed by more sophisticated models" in their analysis of exchange rates, by evaluating out-of-sample predictions, although this model is found inferior to the ones that can accommodate a leverage effect when analyzing IBM stock returns.  

The GARCH(p, q) process models conditional variance $\sigma_t^2$, making it possible for the variance to be dependent on its own past lags. The letters *p* and *q* determine the order of the model, with *q* representing the number of past conditional variance lags directly influencing itself in period *t* and *p*, the number of past "innovations" that directly influence the conditional variance in time *t*, where an innovation is defined as the mean-corrected return, or in the case of this study, the mean-corrected log return. As it is not the objective nor the focus of this work, GARCH of higher orders will not be presented here, only the specific case of interest, the GARCH(1, 1), but a detailed explanation can be found directly in @Bollerslev86, or in @Tsay. 

The GARCH(1, 1), therefore, as @Tsay presented, relies on past information to determine the present conditional volatility. Defining the innovations for asset *i* as $a_{i,t} = r_{i,t} - \mu_{i,t}$, where $\mu_{i,t}$ is the mean of the returns, the model can be formalized as

\begin{equation}
(\#eq:garcha)
a_{i, t} = \sigma_{i, t} \epsilon_{i, t}
\end{equation}

\begin{equation}
(\#eq:garchs)
\sigma_{i, t}^2 = \alpha_{0, i} + \alpha_{1, i} a_{i, t - 1}^2 + \beta_{1, i} \sigma_{i, t - 1}^2,
\end{equation}

where $\epsilon_{i,t}$ is assumed to be an i.i.d. random variable following a Student's *t*-distribution, $\alpha_{0,i} > 0$, $\alpha_{1, i} \geq 0$ and $\beta_{1,i} \geq 0$. Finally, it is necessary that $\alpha_{0,i} + \beta_{1, i} < 1$, to ensure the unconditional variance of $a_{t, i}$ is finite while the conditional variance $\sigma_{i, t}^2$ is allowed from period to period. 

It can be seen that in this model a spike in $a_{i, t-1}^2$ or in $\sigma_{i, t-1}^2$ will impact $\sigma_{i, t}^2$ positively, or, in other words, large innovations or conditional variance in time *t - 1* tend to be followed by large innovations in time *t*, since an increase in $\sigma_{i, t}^2$ leads to a higher $a_{i, t}$, making it possible for volatility clusters to occur as they do in financial markets, more noticeably in crisis periods, such as the global financial crisis (2007-2008) and the more recent 2020 stock market crash caused by the COVID-19 pandemic.

For its reasonable forecasting power, allied with its simplicity and parsimony two GARCH(1, 1) models, with *t*-distributed innovations to account for heavier tails, are estimated for the market returns estimates derived from the market capitalization and from the PCA described in Sections \@ref(mcap) and \@ref(pca), respectively. Since this model serves only for comparison purposes, acting as a benchmark for the realized volatility measures, the obtained parameters are not in focus in this work, although being presented in Appendix \@ref(agarch).

Finally, the Fama-MacBeth regression, which serves the purpose of testing rather the cryptocurrency market's volatility is a significant factor in determining assets returns, is presented in the next subsection.

## FAMA-MACBETH REGRESSION {#fmb}




# RESULTS {#res}





# CONCLUSION {#conc}


# BIBLIOGRAPHY {-}

<div id="refs"></div>


# (APPENDIX) Appendix {-}

# Additional Data Description

## Series' Data Availability Information {#adata}
```{r}
readr::read_rds(paste0(path, "full_summ_table.rds")) %>%
  mutate(`Initial Date` = lubridate::as_date(`Initial Date`)) %>% 
  kable(caption = "Series' Initial Dates and Total Available Observations", digits = 4)
```

## Series' Summary Statistics {#asumm}

```{r retssumm}
kable(readr::read_rds(paste0(path, "tablea13.rds")), caption = "$r_{i,\ t}$ summary statistics",
      digits = 4)
```

```{r rvssumm}
kable(readr::read_rds(paste0(path, "tablea11.rds")), caption = "$RV_{i,\ t}$ summary statistics",
      digits = 4)

```

```{r rvolsumm}
kable(readr::read_rds(paste0(path, "tablea12.rds")), caption = "$RVOL_{i,\ t}$ summary statistics",
      digits = 4)
```

## Series' Correlation Matrix {#acor}
```{r}
kable(readr::read_rds(paste0(path, "full_cor.rds")), caption = "Full sample 5 minute correlation matrix",
      digits = 4)
```

## PCA Summary Statistics {#apca}

## GARCH Model Outputs {#agarch}

```{r}
mkt_ret <- readr::read_rds("Data/mkt_ret.rds")
gspec <- rugarch::ugarchspec(distribution.model = "std", mean.model = list(armaOrder = c(0, 0)),
                             variance.model = list(model = "sGARCH", garchOrder = c(1, 1)))
rugarch::ugarchfit(gspec, mkt_ret$mkt_ret)
```

```{r}
pca_mkt <- readr::read_rds("Data/pca_mkt.rds")
rugarch::ugarchfit(gspec, pca_mkt$mkt_ret)
```


Not used

\begin{equation}
(\#eq:r)
R_i = \begin{bmatrix}
r_{i,\ 1}\\
r_{i,\ 2}\\
... \\
r_{i,\ T}
\end{bmatrix}
\end{equation}


