---
title: "TCC"
author: "Rodrigo Viale"
date: "28/09/2021"
bibliography: refs.bib  
#csl: abnt.csl
output:
  bookdown::html_document2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, 
                      cache = TRUE)
```

```{r library}
library(tidyverse)
library(knitr)
```

# Introduction {#intro}

A alocação de carteiras de investimento de maneira assertiva é uma tarefa de difícil execução, uma vez que envolve invariavelmente uma pluralidade de riscos. O risco de mercado em particular nunca pode ser completamente eliminado, porém, muito se discute em termos de seu controle e minimização, principalmente através de diversificação, meio esse que depende do mapeamento correto das correlações entre os ativos. Portanto, torna-se necessária, em um processo de construção de carteiras visando a otimização de portfólios, não só a estimação da matriz de covariâncias de maneira assertiva, mas também de medidas de volatilidade precisas.

Um método muito comum e popularizado na literatura que trata da previsão de volatilidade é o GARCH (*General Autoregressive Conditional Heteroskedasticity*), introduzido por @Bollersev86 e que é empregado em retornos diários. GARCH-type models, however, tend to overpredict volatility, as documented by @Nomikos11 when dealing with petroleum futures' time series. These models, therefore, present a slow response after a volatility shock passes, taking time for the estimates to go down.

With the growing amount, availability and managebility of data at higher frequencies (intraday) than the daily one, a richer sample covariance matrix can be estimated, leading ultimately to the construction of a matrix based on realized measures. 

Cryptocurrencies have gained notoriety over the last few years, especially because of the appreciation of Bitcoin, which had an incredible peak in 2018 that was only reached and surpassed by the end of 2020. These alternative assets are traded worldwide in various *exchanges*, private platforms that bare similarities to traditional stock and futures exchanges, like connecting buyers and sellers, but also some pecularities, like unlimited trading 24 hours a day every day of the year, which increases the amount of data per day, since negotiation is not limited to a specific time frame of each day. From 2018 many new digital currencies were introduced, each with a different purpose. These have also had noteworthy appreciation in general, with the total market cap of 50 most valued cryptocurrencies having reached over 1,9 trillion dollars ^[Source: Coinmarketcap, in September 19, 2021]. These higher returns when compared to traditional assets, however, are attained only by the increased volatility that predominates in this market.

This study aims to verify if this additional volatility is a significant factor in determining cryptocurrencies' returns and, simultaneously, if there are benefits to using high frequency data for the covariance matrix estimation, instead of a daily one.

In Chapter \@ref(litrev), a literature review about the matter is introduced, Chapter \@ref(data) briefly describes the data set, Chapter \@ref(empmet) presents the empirical methodology applied in this work, Chapter \@ref(res) presents the obtained results and finally, Chapter \@ref(conc) concludes.

# Literature Review {#litrev}

# Data Description {#data}

The data used in this work consists of ten different cryptocurrency minute-by-minute price series obtained from Binance's API ^[Source: https://api.binance.com/] and negotiated in this exchange, which is currently the largest one in the world in terms of daily trading volume of cryptocurrencies ^[Source: CoinMarketCap, at https://coinmarketcap.com/rankings/exchanges/]. It is also one of the world leaders in terms of number of "markets", where a "market" is defined as the pair of currencies that are being traded.

These cryptocurrencies are listed in Table \@ref(tab:inidates), along with each series' initial dates available through Binance's API and its number of observations. All series are in a minute-by-minute basis, with the longest one, Bitcoin (BTC), having 2,051,078 observations, and the shortest one, Filecoin (FIL), 392,166 observations. The last date for all series is July 31, 2021. 

```{r inidates}
path <- "C:/Users/rodri/OneDrive/Documents/Academics/Trabalho de Conclusão de Curso/tcc/Print/"
kable(readr::read_rds(paste0(path, "table311.rds")), caption = "Series' Initial Dates, Number of Observations and NAs")
```

From this minute-by-minute data set, 5-min closing prices series were constructed, which were then used to compute 5-min realized returns, $r_{i,\ t}$, realized variances, $RV_{i,\ t}$, and realized volatilities, $RVOL_{i,\ t}$ for each $i$ series, according to the formulas that will be presented in Section \@ref(measures). Summary statistics for these measures for each series can be found in Appendix \@ref(asumm).

At the same time, a daily closing prices data set is constructed, which will be used for the GARCH computation, for comparison purposes.

In order to create a synthetic index to represent the "crypto market", the daily market capitalization of each analyzed currency is also obtained from CoinMarketCap and used to create weights for each asset as will be described in Section \@ref(syntwei).

# Methodology {#empmet}

The methodology used in this study combines realized measures, which are presented in Section \@ref(measures), applied to real series, i.e. the cryptocurrencies that make up the initial data set, but also to fictitious series, that are created trough the assets' weighting techniques described in Section \@ref(syntwei), constituting the final data set. At the same time, a GARCH volatility estimate is computed, according to what is depicted in Section \@ref(garch). Lastly, with this final data set and the GARCH estimates, two Fama-MacBeth regressions, as presented in Section \@ref(fmb), are computed.

## Realized Mesures {#measures}

For the purposes of this study, individual asset log returns are computed from the sum of the 5-min log returns for each cryptocurrency $i$, according to the formula below.

\begin{equation}
(\#eq:ri)
r_{i,\ t} = \sum_{j = 1}^{m} r_{i,\ t - 1 + j n}\\
\end{equation}

where $t$ represents a day, $n$ is a fraction of a trading session associated with the sampling frequency (since 5-min returns are being used and there are 1440 minutes in one day, $n = \frac{1}{(1440/5)} = \frac{1}{288}$) and $m$ represents the amount of observations in on day ($m = \frac{1}{n} = 288$).

Following the conclusion from Liu et al. (2015) that it is very difficult to significantly beat a simple 5-minute realized variance ($RV$) when it comes to price variation estimators constructed from high-frequency data, this realized measure is therefore taken for the analysis conducted in this study. This estimator consists of the sum of squared 5-minute returns for each day $t$ and asset $i$, as in the formula below.

\begin{equation}
(\#eq:rv)
RV_{i,\ t} = \sum_{j = 1}^{m} r_{i,\ t - 1 + j n}^{2}
\end{equation}

where $n$ is a fraction of a trading session associated with the sampling frequency (since 5-min $RV$ is being used and there are 1440 minutes in one day, $n = \frac{1}{(1440/5)} = \frac{1}{288}$) and $m$ represents the amount of observations in on day ($m = \frac{1}{n} = 288$).

The volatility $RVOL_{i,\ t}$ provided by this estimator is then simply the square root of each $RV_{i,\ t}$.

\begin{equation}
(\#eq:rvol)
RVOL_{i,\ t} = \sqrt{RV_{i, t}}
\end{equation}

## Synthetic Market Estimates and Weighting Methods {#syntwei}

In order to create synthetic indices that are able to represent the the overall cryptocurrency market, it becomes necessary to weight the assets in order to create this index. Two methods, therefore, are employed as weighting factors: the daily market capitalization for each asset and the weights derived from the application of the Principal Component Analysis (PCA).

### Estimation Based on Market Capitalization

From the daily market capitalization series, weights $w_{i,\ t}$ are estimated such that

\begin{equation}
(\#eq:wi)
w_{i,\ t}^{(MC)} = \frac{MC_{i, t}}{\sum_{j = 1}^K MC_{j, t}}\\
\end{equation}

\begin{equation}
(\#eq:wmc)
W_{MC,\ t}=
\begin{bmatrix}
w_{1,\ t} \\
w_{2,\ t} \\
... \\
w_{K,\ t} \\
\end{bmatrix}
\end{equation}

where $MC_{i,\ t}$ is the market capitalization for asset $i$ in period $t$.

These weights are then combined with the assets' returns in equation \@ref(eq:ri), computed previously to obtain an estimate of *market* returns $R_{m,\ t}^{(MC)}$ such as

\begin{equation}
(\#eq:caprm)
r_{m,\ t}^{(MC)} = \sum_{i = 1}^K (r_{i,\ t} w_{i,\ t})\\
\end{equation}

\begin{equation}
(\#eq:capRm)
R_{m}^{(MC)} =
\begin{bmatrix}
r_{m,\ 1}^{(MC)} \\
r_{m,\ 2}^{(MC)} \\
... \\
r_{m,\ T}^{(MC)}
\end{bmatrix} 
=
\begin{bmatrix}
\sum_{i = 1}^K (r_{i,\ 1} w_{i,\ 1}) \\
\sum_{i = 1}^K (r_{i,\ 2} w_{i,\ 2}) \\
... \\
\sum_{i = 1}^K (r_{i,\ T} w_{i,\ T})
\end{bmatrix}.
\end{equation}

This vector will be the first regressor in the Fama-MacBeth estimation.

Testing the market's volatility as a driver of returns is the main goal of this work, however, obtaining an estimate for the market's volatility is quite more tricky. The variance can not be weighted in the same fashion as what was done for assets' returns, because of the covariance between assets ^[Explain why variance can't be multiplied and summed up.], and also, there is no 5-minute market returns series (only daily), where the sum of squared returns could be taken, similarly as to what was done with the individual cryptocurrencies. To obtain an estimate for the market's 5-minute realized variance, therefore, firstly the 5-minute sample covariance matrix for each period must be estimated

\begin{equation}
(\#eq:rcovix)
RCov_{t} = 
\begin{bmatrix} 
s_{11,\ t}^2 & s_{12,\ t}^2 & ... & s_{1K,\ t}^2\\
s_{21,\ t}^2 & s_{22,\ t}^2 & ... & s_{2K,\ t}^2\\
... & ... & ... & ...\\
s_{K1,\ t}^2 & s_{K2,\ t}^2 & ... & s_{KK,\ t}^2\\
\end{bmatrix},
\end{equation}

where $s_{ij,\ t}^2$ denotes the 5-minute sample covariance between assets $i$ and $j$ in day $t$. This matrix can then be simply weighted by the $W_{MC,\ t}$ vectors obtained from the assets' market capitalization in equation \@ref(eq:wmc) in the following way.

\begin{equation}
(\#eq:wcovix)
RV_{m,\ t}^{(MC)} = W_{MC,\ t}^T \times RCov_{t} \times W_{MC,\ t},
\end{equation}

where superscript $T$ is denotes the transposed of the vector in question. The volatility for each period $t$ is therefore obtained simply by taking square root of the obtained realized variance estimate: 

\begin{equation}
(\#eq:caprvol)
RVOL_{m,\ t}^{(MC)} = \sqrt{RV_{m,\ t}^{(MC)}}
\end{equation}

### Estimation Based on Principal Component Analysis

An alternative method used to obtain an estimate for the market's returns and volatility is through Principal Component Analysis (PCA), introduced by @Pearson1901. In a context of closely related variables such as this data set (see the series' correlation matrix in Appendix \@ref(acor), @Brooks19 noted that PCA can be particularly useful, because it can transform the $K$ series into a new set of $K$ uncorrelated variables, by taking linear combinations of the original data set. In other terms, as Brooks presents

\begin{array}{ccccccccc}
(\#eq:pca)
p_1  & = & \alpha_{1,\ 1} x_1 & + & \alpha_{1,\ 2} x_2\ & + & ... & + & \alpha_{1,\ K} x_K \\
p_2  & = & \alpha_{2,\ 1} x_1 & + & \alpha_{2,\ 2} x_2\ & + & ... & + & \alpha_{2,\ K} x_K \\
...  & = & ...                & + & ...                 & + & ... & + & ... \\
p_K  & = & \alpha_{K,\ 1} x_1 & + & \alpha_{K,\ 2} x_2\ & + & ... & + & \alpha_{K,\ K} x_K \\
\end{array}

where $p_i$ and $x_i$, represent, respectively, the $i$ principal component and original variable, and $\alpha_{i,\ j}$ denotes the coefficient for variable $j$ in the principal component $i$.

## GARCH Model {#garch}


## Fama-MacBeth Regression {#fmb}




# Results {#res}





# Conclusion {#conc}


# References {-}

<div id="refs"></div>


# (APPENDIX) Appendix {-}

# Additional Data Description
## Series' Summary Statistics {#asumm}

```{r retssumm}
kable(readr::read_rds(paste0(path, "tablea13.rds")), caption = "$r_{i,\ t}$ summary statistics",
      digits = 4)
```

```{r rvssumm}
kable(readr::read_rds(paste0(path, "tablea11.rds")), caption = "$RV_{i,\ t}$ summary statistics",
      digits = 4)

```

```{r rvolsumm}
kable(readr::read_rds(paste0(path, "tablea12.rds")), caption = "$RVOL_{i,\ t}$ summary statistics",
      digits = 4)
```

## Series' Correlation Matrix {#acor}
```{r}
kable(readr::read_rds(paste0(path, "full_cor.rds")), caption = "Full sample 5 minute correlation matrix",
      digits = 4)
```

Not used

\begin{equation}
(\#eq:r)
R_i = \begin{bmatrix}
r_{i,\ 1}\\
r_{i,\ 2}\\
... \\
r_{i,\ T}
\end{bmatrix}
\end{equation}


